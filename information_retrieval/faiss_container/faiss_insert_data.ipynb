{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesting embeddings into Faiss index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing through the JSONL files, extracting the bioBERT embeddings and the corresponding PMIDs. Creating a Faiss index with the embeddings and a CSV file storing PMIDs with the corresponding Faiss index id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONL files: 100%|██████████| 140/140 [59:46<00:00, 25.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index successfully written to: /home/ubuntu/data/faiss_indices/bioBERT/faiss_indices/bioBERT_index.index\n",
      "CSV file successfully written to: /home/ubuntu/data/faiss_indices/bioBERT/PMIDs/bioBERT_pmids.csv\n"
     ]
    }
   ],
   "source": [
    "# Directory setup\n",
    "index_directory = \"/home/ubuntu/data/faiss_indices/bioBERT\"\n",
    "index_file = \"bioBERT_index.index\"\n",
    "index_path = os.path.join(index_directory, index_file)\n",
    "csv_file = \"/home/ubuntu/data/faiss_indices/bioBERT/bioBERT_pmids.csv\"\n",
    "\n",
    "# Ensure the index directory exists\n",
    "if not os.path.exists(index_directory):\n",
    "    os.makedirs(index_directory)\n",
    "\n",
    "# Dimensions of the embeddings\n",
    "d = 768  \n",
    "\n",
    "# Initialize the Faiss index (Flat L2-Index)\n",
    "index = faiss.IndexFlatL2(d)\n",
    "\n",
    "# Initialize the CSV file for PMIDs\n",
    "csv_path = csv_file\n",
    "csv_rows = []\n",
    "\n",
    "# Collecting all JSONL files in the current directory\n",
    "source_directory = Path('/home/ubuntu/data/pubmed')\n",
    "\n",
    "# Retrieve and sort the files based on their numerical order in filenames\n",
    "sorted_files = sorted(source_directory.glob('*.jsonl'), key=lambda x: int(x.stem.split('n')[-1]))\n",
    "\n",
    "# Processing sorted files with progress display\n",
    "for file_name in tqdm(sorted_files, desc=\"Processing JSONL files\"):\n",
    "    with open(file_name, 'r') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                embeddings = data.get('embeddings')\n",
    "                pmid = int(data.get('PMID'))\n",
    "                \n",
    "                # If embeddings and PMID are present, add them to the index\n",
    "                if embeddings and pmid:\n",
    "                    embeddings = np.array(embeddings, dtype='float32').reshape(1, -1)  # Convert to NumPy array and reshape\n",
    "                    index.add(embeddings)\n",
    "                    \n",
    "                    # Add PMIDs, filenames, and index numbers for ordering to the CSV\n",
    "                    index_num = index.ntotal - 1  # Index number of the last added embedding\n",
    "                    csv_rows.append([pmid, file_name.name, index_num])\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON in file {file_name}: {e}\")\n",
    "\n",
    "# Write the index to a file\n",
    "faiss.write_index(index, index_path)\n",
    "\n",
    "print(f\"Index successfully written to: {index_path}\")\n",
    "\n",
    "# Write PMIDs to CSV file\n",
    "with open(csv_path, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['PMID', 'Filename', 'Index'])\n",
    "    csv_writer.writerows(csv_rows)\n",
    "\n",
    "print(f\"CSV file successfully written to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index('faiss_indices/PM_index.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10  # Number of nearest neighbors\n",
    "\n",
    "query = np.random.rand(768).tolist()\n",
    "\n",
    "distances, indices = index.search(query, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Response: {'distances': [[348.77490234375, 348.9889221191406, 349.5247497558594, 349.7203369140625, 349.90228271484375, 349.9190979003906, 350.23382568359375, 350.36578369140625, 350.47930908203125, 350.5979309082031]], 'indices': [[470115, 1932016, 473742, 469270, 1405245, 670332, 1715754, 2382674, 1707872, 2141577]]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# URL of the Flask endpoint\n",
    "url = 'http://localhost:5000/search'\n",
    "\n",
    "# Generate a random vector of length 768\n",
    "random_vector = np.random.rand(768).tolist()  # Convert numpy array directly to list\n",
    "\n",
    "# Data for the POST request\n",
    "data = {\n",
    "    'queries': [random_vector]  # Ensure this is a list of lists\n",
    "}\n",
    "\n",
    "# Convert data to JSON before sending as POST request\n",
    "json_data = json.dumps(data)\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(url, headers={'Content-Type': 'application/json'}, data=json_data)\n",
    "\n",
    "# Output the response\n",
    "print('Status Code:', response.status_code)\n",
    "print('Response:', response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
